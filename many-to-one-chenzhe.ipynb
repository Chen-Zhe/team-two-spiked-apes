{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1FWITFR4kdt"
   },
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMrhEjZQNpaf"
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVfVlcXvck7x",
    "outputId": "b6b41ae1-c9e5-49b9-da5a-f318dc9ab12c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "import torchvision as vis\n",
    "import sys\n",
    "\n",
    "# torch.manual_seed(117850791)\n",
    "is_windows = sys.platform == \"win32\"\n",
    "has_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if has_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class FlatImageData(vis.datasets.VisionDataset):\n",
    "  def __init__(self, root, transform, validation_reserved_images=31136):\n",
    "    self.root = root\n",
    "    self.images = os.listdir(root)\n",
    "    self.images.sort(key=lambda x: int(x[6:-5]))# sort by frame no.\n",
    "    self.transform = transform\n",
    "    self.training_mode = True\n",
    "    self.reserved_images = validation_reserved_images\n",
    "        \n",
    "  def __len__(self):\n",
    "    if self.training_mode:\n",
    "      return len(self.images) - self.reserved_images\n",
    "    else:\n",
    "      return self.reserved_images\n",
    "    \n",
    "  def pil_loader(self, path: str) -> Image.Image:\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    if self.training_mode:\n",
    "      index += self.reserved_images\n",
    "    \n",
    "    image_name = self.images[index]\n",
    "    image_path = f\"{self.root}/{image_name}\"\n",
    "    image = self.pil_loader(image_path)\n",
    "    if self.transform is not None:\n",
    "         image = self.transform(image)\n",
    "\n",
    "    return image\n",
    "    \n",
    "class ImageWindow(data.Dataset):\n",
    "  def __init__(self, dataset, wide_window_size):\n",
    "    self.dataset = dataset\n",
    "    self.wide_window_size = wide_window_size\n",
    "    self.window_offset = 0\n",
    "  \n",
    "  def shuffle(self):\n",
    "    self.window_offset = torch.randint(0, self.wide_window_size, (1,)).item()\n",
    "  \n",
    "  def __len__(self):\n",
    "    return (len(self.dataset) - self.window_offset) // self.wide_window_size\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    image_index_start = self.window_offset + index * self.wide_window_size\n",
    "    images = [self.dataset[image_idx] for image_idx in\n",
    "              range(image_index_start, image_index_start + self.wide_window_size, 1)]\n",
    "    return torch.stack(images, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FlatImageData\n",
       "    Number of datapoints: 160745\n",
       "    Root location: /home/ubuntu/data/knnw-256p"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = FlatImageData(root=\"/home/ubuntu/data/knnw-256p\",\n",
    "                             transform=vis.transforms.Compose([\n",
    "                               vis.transforms.RandomHorizontalFlip(),\n",
    "                               vis.transforms.RandomApply(nn.ModuleList([\n",
    "                                 vis.transforms.RandomAffine(degrees=15),\n",
    "                                 vis.transforms.CenterCrop((200, 200))\n",
    "                               ]), p=0.5),\n",
    "                               vis.transforms.ToTensor(),\n",
    "                               nn.AdaptiveAvgPool2d((64, 64))\n",
    "                             ])\n",
    "                            )\n",
    "# dataset.training_mode=False\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = ImageWindow(dataset, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjCIyjpWdqGw"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_store = \"model_checkpoints\"\n",
    "\n",
    "class StoredModel:\n",
    "  def __init__(self, model, optimizer, scheduler, criterion):\n",
    "    self.model = model\n",
    "    self.optimizer = optimizer\n",
    "    self.scheduler = scheduler\n",
    "    self.criterion = criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from typing import List, Callable, Union, Any, TypeVar, Tuple\n",
    "Tensor = TypeVar('torch.tensor')\n",
    "\n",
    "class BetaVAE(nn.Module):\n",
    "\n",
    "    num_iter = 0 # Global static variable to keep track of iterations\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 latent_dim: int,\n",
    "                 hidden_dims: List = None,\n",
    "                 beta: int = 4,\n",
    "                 gamma:float = 1000.,\n",
    "                 max_capacity: int = 25,\n",
    "                 Capacity_max_iter: int = 1e5,\n",
    "                 loss_type:str = 'B',\n",
    "                 **kwargs) -> None:\n",
    "        super(BetaVAE, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.loss_type = loss_type\n",
    "        self.C_max = torch.Tensor([max_capacity])\n",
    "        self.C_stop_iter = Capacity_max_iter\n",
    "\n",
    "        modules = []\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 64, 128, 256, 512]\n",
    "\n",
    "        # Build Encoder\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels=h_dim,\n",
    "                              kernel_size= 3, stride= 2, padding  = 1),\n",
    "                    nn.BatchNorm2d(h_dim),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "            \n",
    "        modules.append(nn.Flatten())\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        \n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1]*4, latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dims[-1]*4, latent_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1] * 4)\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(hidden_dims[i],\n",
    "                                       hidden_dims[i + 1],\n",
    "                                       kernel_size=3,\n",
    "                                       stride = 2,\n",
    "                                       padding=1,\n",
    "                                       output_padding=1),\n",
    "                    nn.BatchNorm2d(hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(\n",
    "                            nn.ConvTranspose2d(hidden_dims[-1],\n",
    "                                               hidden_dims[-1],\n",
    "                                               kernel_size=3,\n",
    "                                               stride=2,\n",
    "                                               padding=1,\n",
    "                                               output_padding=1),\n",
    "                            nn.BatchNorm2d(hidden_dims[-1]),\n",
    "                            nn.LeakyReLU(),\n",
    "                            nn.Conv2d(hidden_dims[-1], out_channels= 3,\n",
    "                                      kernel_size= 3, padding= 1))\n",
    "\n",
    "    def encode(self, inputs: Tensor) -> List[Tensor]:\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x Window x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size, window_size, C, H, W = inputs.shape\n",
    "        \n",
    "        result = self.encoder(inputs.view(-1, C, H, W))\n",
    "        \n",
    "        # use average\n",
    "        conmbined_features = result.view(batch_size, window_size, -1).mean(dim=1)\n",
    "        \n",
    "#         # sliding window\n",
    "#         for batch_i in range(batch_size):\n",
    "#           for window_i in range(wide_window_size - self.window_size + 1):\n",
    "#             concated_features.append(result[batch_i, window_i:window_i+self.window_size, :].flatten())\n",
    "            \n",
    "#         concated_features = torch.stack(concated_features)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(conmbined_features)\n",
    "        log_var = self.fc_var(conmbined_features)\n",
    "\n",
    "        return (inputs, mu, log_var)\n",
    "\n",
    "    def decode(self, z: Tensor) -> Tensor:\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, 512, 2, 2)\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "        return result\n",
    "\n",
    "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Will a single z be enough to compute the expectation\n",
    "        for the loss??\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, inputs: Tensor, **kwargs) -> Tensor:\n",
    "        inputs, mu, log_var = self.encode(inputs)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        \n",
    "        self.current_inputs = inputs\n",
    "        self.current_mu = mu\n",
    "        self.current_log_var = log_var\n",
    "        self.current_recon = self.decode(z)\n",
    "        \n",
    "        return self.current_recon\n",
    "\n",
    "    def loss(self, *args, **kwargs) -> dict:\n",
    "        self.num_iter += 1\n",
    "        recons = self.current_recon\n",
    "        input = self.current_inputs\n",
    "        mu = self.current_mu\n",
    "        log_var = self.current_log_var\n",
    "        kld_weight = kwargs['kld_weight']  # Account for the minibatch samples from the dataset\n",
    "        \n",
    "        batch_size = recons.shape[0]\n",
    "        window_size = input.shape[1]\n",
    "        recons_loss =F.binary_cross_entropy_with_logits(recons.unsqueeze(dim=1).expand_as(input),\n",
    "                                                        input, reduction='sum') / batch_size / window_size\n",
    "  \n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "\n",
    "        if self.loss_type == 'H': # https://openreview.net/forum?id=Sy2fzU9gl\n",
    "            loss = recons_loss + self.beta * kld_weight * kld_loss\n",
    "        elif self.loss_type == 'B': # https://arxiv.org/pdf/1804.03599.pdf\n",
    "            self.C_max = self.C_max.to(input.device)\n",
    "            C = torch.clamp(self.C_max/self.C_stop_iter * self.num_iter, 0, self.C_max.data[0])\n",
    "            loss = recons_loss + self.gamma * kld_weight * (kld_loss - C).abs()\n",
    "        else:\n",
    "            raise ValueError('Undefined loss type.')\n",
    "\n",
    "        return {'loss': loss, 'Reconstruction_Loss':recons_loss, 'KLD':kld_loss}\n",
    "\n",
    "    def sample(self,\n",
    "               num_samples:int,\n",
    "               current_device: int, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the latent space and return the corresponding\n",
    "        image space map.\n",
    "        :param num_samples: (Int) Number of samples\n",
    "        :param current_device: (Int) Device to run the model\n",
    "        :return: (Tensor)\n",
    "        \"\"\"\n",
    "        z = torch.randn(num_samples,\n",
    "                        self.latent_dim)\n",
    "\n",
    "        z = z.to(current_device)\n",
    "\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "    def generate(self, x: Tensor, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Given an input image x, returns the reconstructed image\n",
    "        :param x: (Tensor) [B x C x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vozrJJ1kKHdY",
    "outputId": "0812e473-8716-4219-d653-fce0a462a0ed"
   },
   "outputs": [],
   "source": [
    "def load_model(model_id, specific_epoch = None):\n",
    "  global optimizer, scheduler\n",
    "  epoch_start = -1\n",
    "  for checkpoint in os.listdir(f\"{model_store}/{model_id}\"):\n",
    "    if not checkpoint.startswith(\"epoch\"):\n",
    "      continue\n",
    "    epoch = int(checkpoint.split(\"_\")[1])\n",
    "    if specific_epoch is None:\n",
    "      # find the latest\n",
    "      if epoch > epoch_start:\n",
    "        epoch_start = epoch\n",
    "        last_checkpoint = checkpoint\n",
    "    else:\n",
    "      if epoch == specific_epoch:\n",
    "        epoch_start = epoch\n",
    "        last_checkpoint = checkpoint\n",
    "        break\n",
    "\n",
    "  if epoch_start == -1:\n",
    "    print(f\"No checkpoints available for {model_id}!\")\n",
    "    return -1, None\n",
    "  else:\n",
    "    epoch_start += 1\n",
    "    print(f\"resuming from last checkpoint {last_checkpoint}\")\n",
    "    data = torch.load(f\"{model_store}/{model_id}/{last_checkpoint}\")\n",
    "    \n",
    "    model = data.model\n",
    "    optimizer = data.optimizer\n",
    "    scheduler = data.scheduler\n",
    "    criterion = data.criterion\n",
    "    \n",
    "    model.to(device)\n",
    "    return epoch_start, model, criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume from checkpoint or a new model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-pAgeJrlcYk7",
    "outputId": "d3478786-ee0c-4bf5-e5c5-3546a102e2c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BetaVAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (5): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (fc_mu): Linear(in_features=2048, out_features=128, bias=True)\n",
      "  (fc_var): Linear(in_features=2048, out_features=128, bias=True)\n",
      "  (decoder_input): Linear(in_features=128, out_features=2048, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "  )\n",
      "  (final_layer): Sequential(\n",
      "    (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             896\n",
      "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
      "         LeakyReLU-3           [-1, 32, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 16, 16]          18,496\n",
      "       BatchNorm2d-5           [-1, 64, 16, 16]             128\n",
      "         LeakyReLU-6           [-1, 64, 16, 16]               0\n",
      "            Conv2d-7            [-1, 128, 8, 8]          73,856\n",
      "       BatchNorm2d-8            [-1, 128, 8, 8]             256\n",
      "         LeakyReLU-9            [-1, 128, 8, 8]               0\n",
      "           Conv2d-10            [-1, 256, 4, 4]         295,168\n",
      "      BatchNorm2d-11            [-1, 256, 4, 4]             512\n",
      "        LeakyReLU-12            [-1, 256, 4, 4]               0\n",
      "           Conv2d-13            [-1, 512, 2, 2]       1,180,160\n",
      "      BatchNorm2d-14            [-1, 512, 2, 2]           1,024\n",
      "        LeakyReLU-15            [-1, 512, 2, 2]               0\n",
      "          Flatten-16                 [-1, 2048]               0\n",
      "           Linear-17                  [-1, 128]         262,272\n",
      "           Linear-18                  [-1, 128]         262,272\n",
      "           Linear-19                 [-1, 2048]         264,192\n",
      "  ConvTranspose2d-20            [-1, 256, 4, 4]       1,179,904\n",
      "      BatchNorm2d-21            [-1, 256, 4, 4]             512\n",
      "        LeakyReLU-22            [-1, 256, 4, 4]               0\n",
      "  ConvTranspose2d-23            [-1, 128, 8, 8]         295,040\n",
      "      BatchNorm2d-24            [-1, 128, 8, 8]             256\n",
      "        LeakyReLU-25            [-1, 128, 8, 8]               0\n",
      "  ConvTranspose2d-26           [-1, 64, 16, 16]          73,792\n",
      "      BatchNorm2d-27           [-1, 64, 16, 16]             128\n",
      "        LeakyReLU-28           [-1, 64, 16, 16]               0\n",
      "  ConvTranspose2d-29           [-1, 32, 32, 32]          18,464\n",
      "      BatchNorm2d-30           [-1, 32, 32, 32]              64\n",
      "        LeakyReLU-31           [-1, 32, 32, 32]               0\n",
      "  ConvTranspose2d-32           [-1, 32, 64, 64]           9,248\n",
      "      BatchNorm2d-33           [-1, 32, 64, 64]              64\n",
      "        LeakyReLU-34           [-1, 32, 64, 64]               0\n",
      "           Conv2d-35            [-1, 3, 64, 64]             867\n",
      "          BetaVAE-36            [-1, 3, 64, 64]               0\n",
      "================================================================\n",
      "Total params: 3,937,635\n",
      "Trainable params: 3,937,635\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.14\n",
      "Forward/backward pass size (MB): 6.08\n",
      "Params size (MB): 15.02\n",
      "Estimated Total Size (MB): 21.24\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary_string\n",
    "model_id = \"many_to_one_mean_B_loss_64x64_10_latent\"\n",
    "\n",
    "model = BetaVAE(3, 128, loss_type=\"B\")\n",
    "\n",
    "epoch_start = 0\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "model_spec = summary_string(model, (3, 3, 64, 64))[0]\n",
    "print(model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(f\"{model_store}/{model_id}\")\n",
    "# save model summary to a txt file\n",
    "with open(f\"{model_store}/{model_id}/model_spec.txt\", \"w\") as file:\n",
    "  file.write(str(model) + \"\\n\")\n",
    "  file.write(model_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load a trained model from checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resuming from last checkpoint epoch_23_tr-loss_25402.493092\n",
      "BetaVAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (5): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (fc_mu): Linear(in_features=8192, out_features=128, bias=True)\n",
      "  (fc_var): Linear(in_features=8192, out_features=128, bias=True)\n",
      "  (decoder_input): Linear(in_features=128, out_features=8192, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "  )\n",
      "  (final_layer): Sequential(\n",
      "    (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_id = \"many_to_one_mean_H_loss_128x128_128_latent_beta_2.5\"\n",
    "epoch_start, model, criterion = load_model(model_id)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear GPU cache\n",
    "if has_cuda:\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "S3Jw1cHCKHdZ"
   },
   "outputs": [],
   "source": [
    "train_dataloader_args = dict(batch_size=64,\n",
    "                             num_workers=0 if is_windows else 4) if has_cuda else dict(batch_size=64)\n",
    "train_dataloader_args[\"shuffle\"] = True\n",
    "\n",
    "train_dataloader = data.DataLoader(window, **train_dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from itertools import chain\n",
    "\n",
    "num_epochs = 40\n",
    "\n",
    "if epoch_start == 0:\n",
    "  # define only at the start of the training\n",
    "  \n",
    "  regularization = 2e-5\n",
    "#   learning_rate = 1e-1\n",
    "#   optimizer = optim.SGD(chain(model.parameters(), criterion.parameters()),\n",
    "#                          lr = learning_rate, momentum=0.9, weight_decay=regularization, nesterov=True)\n",
    "  learning_rate = 1e-3\n",
    "  optimizer = optim.Adam(model.parameters(),\n",
    "                         lr = learning_rate, weight_decay=regularization)\n",
    "#   scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 20, gamma = 0.5)\n",
    "  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2,\n",
    "                                                   threshold=0.001)\n",
    "  \n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler() # mix-precision training\n",
    "\n",
    "with open(f\"{model_store}/{model_id}/training_params.txt\", \"w\") as file:\n",
    "  file.write(f\"num_epochs = {num_epochs}\\n\")\n",
    "  file.write(f\"optimizer = {optimizer}\\n\")\n",
    "  file.write(f\"scheduler = {type(scheduler).__name__}({scheduler.state_dict()})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "  param_group['lr'] = 1e-3\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2,\n",
    "                                                threshold=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565,
     "referenced_widgets": [
      "5c0dee334a114a52abd20b7a1b96d568",
      "a533314e9e2f4d23a31c298a0683c486",
      "596b682110674f20934a06addff6d8f6",
      "5ee5b74cab264a4e84bc6e20bc850bc7",
      "1805948e77c0451a9e059c5c4bf179f9",
      "eb87e4d9cb9f49d28a2e070bc7899749",
      "0283c3f6ab8d4db59c360fbdac209a40",
      "9f87e2946789478eafa38e091d34ab37",
      "49e8cce1980b46f69e2271f61680dd47",
      "e4a224892c794b3e830645e2ff44a478",
      "ff8d7ad423514805aa787c690a1af364",
      "4c6fb19bcea64ca6950ab21c526cc7fc",
      "bf1698340c0d43279c1856c571d6cdc6",
      "734209de749448659ab4cd1d83138bbc",
      "80cfd4dc87644e3db22cd48e1a77f6e2",
      "c80f27fe1e4543bf93d95a0592b5caea",
      "0d4725910b274893adc55eb6b921ac0a",
      "f5101a0c7f6447f0a339f48c2d5d50d1",
      "1e7015b74a144561951a104c706ec89e",
      "1644bd1faf584290bfa440f0c91631b3",
      "9bc1b9387d774436ac5e5364564e04ee",
      "07a14eca20f041daae89d7f24a313efb",
      "02768ffc5b6a409e8a498c4d392f32ad",
      "13ca4f4139f049eab3013edc25c5cb1b",
      "3e1997cd529542378c714b0e756228cb",
      "9d28ab07d37b43239c5e4ab76bd42a47",
      "44f69c76d6504365bf2ceea26ddb4cb0",
      "89c64138bb524eb292f61a1f667c2e36",
      "b3616ce23d6e458587a869dcda5b0e65",
      "2173829b4cbe497c9de00d80a7268f5e",
      "9fd5d7540f954a72b1da87f751226d91",
      "3fa5a9ca37344da2be24670c75153355"
     ]
    },
    "id": "7wRgUFh2fGOa",
    "outputId": "53dc92ef-0179-4238-cdbb-8849ba153c55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model: many_to_one_mean_B_loss_64x64_10_latent. Training for 40 epochs\n",
      "Epoch 0\n",
      "Train: 100%|██████████| 838/838 [02:14<00:00,  6.25it/s]\n",
      "{\"Epoch\": 0, \"training loss\": 8747.507996, \"reconstruction loss\": 8210.095212, \"KLD loss\": 0.641461, \"Learning rate\": [0.001]}\n",
      "Epoch 1\n",
      "Train: 100%|██████████| 838/838 [02:14<00:00,  6.23it/s]\n",
      "{\"Epoch\": 1, \"training loss\": 8087.458632, \"reconstruction loss\": 7995.213994, \"KLD loss\": 0.39451, \"Learning rate\": [0.001]}\n",
      "Epoch 2\n",
      "Train: 100%|██████████| 838/838 [02:14<00:00,  6.23it/s]\n",
      "{\"Epoch\": 2, \"training loss\": 7923.292402, \"reconstruction loss\": 7856.261709, \"KLD loss\": 0.567289, \"Learning rate\": [0.001]}\n",
      "Epoch 3\n",
      "Train: 100%|██████████| 838/838 [02:14<00:00,  6.24it/s]\n",
      "{\"Epoch\": 3, \"training loss\": 7791.024082, \"reconstruction loss\": 7731.145271, \"KLD loss\": 0.762325, \"Learning rate\": [0.001]}\n",
      "Epoch 4\n",
      "Train: 100%|██████████| 838/838 [02:14<00:00,  6.24it/s]\n",
      "{\"Epoch\": 4, \"training loss\": 7578.101603, \"reconstruction loss\": 7532.429114, \"KLD loss\": 0.965296, \"Learning rate\": [0.001]}\n",
      "Epoch 5\n",
      "Train: 100%|██████████| 838/838 [02:14<00:00,  6.23it/s]\n",
      "{\"Epoch\": 5, \"training loss\": 7501.634212, \"reconstruction loss\": 7465.46248, \"KLD loss\": 1.165361, \"Learning rate\": [0.001]}\n",
      "Epoch 6\n",
      "Train: 100%|██████████| 838/838 [02:14<00:00,  6.25it/s]\n",
      "{\"Epoch\": 6, \"training loss\": 7470.862721, \"reconstruction loss\": 7425.452802, \"KLD loss\": 1.374763, \"Learning rate\": [0.001]}\n",
      "Epoch 7\n",
      "Train: 100%|██████████| 838/838 [02:14<00:00,  6.24it/s]\n",
      "{\"Epoch\": 7, \"training loss\": 7443.456775, \"reconstruction loss\": 7396.965625, \"KLD loss\": 1.579241, \"Learning rate\": [0.001]}\n",
      "Epoch 8\n",
      "Train: 100%|██████████| 838/838 [02:14<00:00,  6.23it/s]\n",
      "{\"Epoch\": 8, \"training loss\": 7415.33443, \"reconstruction loss\": 7369.423407, \"KLD loss\": 1.789729, \"Learning rate\": [0.001]}\n",
      "Epoch 9\n",
      "Train: 100%|██████████| 838/838 [02:14<00:00,  6.24it/s]\n",
      "{\"Epoch\": 9, \"training loss\": 7404.639492, \"reconstruction loss\": 7354.084835, \"KLD loss\": 1.997695, \"Learning rate\": [0.001]}\n",
      "Epoch 10\n",
      "Train: 100%|██████████| 838/838 [02:14<00:00,  6.23it/s]\n",
      "{\"Epoch\": 10, \"training loss\": 7404.169741, \"reconstruction loss\": 7345.906265, \"KLD loss\": 2.206259, \"Learning rate\": [0.001]}\n",
      "Epoch 11\n",
      "Train: 100%|██████████| 838/838 [02:14<00:00,  6.22it/s]\n",
      "{\"Epoch\": 11, \"training loss\": 7380.488581, \"reconstruction loss\": 7328.958016, \"KLD loss\": 2.41417, \"Learning rate\": [0.001]}\n",
      "Epoch 12\n",
      "Train: 100%|██████████| 838/838 [02:15<00:00,  6.18it/s]\n",
      "{\"Epoch\": 12, \"training loss\": 7388.689521, \"reconstruction loss\": 7325.856297, \"KLD loss\": 2.623233, \"Learning rate\": [0.001]}\n",
      "Epoch 13\n",
      "Train: 100%|██████████| 838/838 [02:15<00:00,  6.17it/s]\n",
      "{\"Epoch\": 13, \"training loss\": 7370.610927, \"reconstruction loss\": 7313.788994, \"KLD loss\": 2.834705, \"Learning rate\": [0.001]}\n",
      "Epoch 14\n",
      "Train: 100%|██████████| 838/838 [02:14<00:00,  6.25it/s]\n",
      "{\"Epoch\": 14, \"training loss\": 7364.964965, \"reconstruction loss\": 7304.792808, \"KLD loss\": 3.040506, \"Learning rate\": [0.001]}\n",
      "Epoch 15\n",
      "Train: 100%|██████████| 838/838 [02:13<00:00,  6.29it/s]\n",
      "{\"Epoch\": 15, \"training loss\": 7353.202109, \"reconstruction loss\": 7294.234254, \"KLD loss\": 3.251131, \"Learning rate\": [0.001]}\n",
      "Epoch 16\n",
      "Train: 100%|██████████| 838/838 [02:13<00:00,  6.28it/s]\n",
      "{\"Epoch\": 16, \"training loss\": 7343.272483, \"reconstruction loss\": 7282.548333, \"KLD loss\": 3.463724, \"Learning rate\": [0.001]}\n",
      "Epoch 17\n",
      "Train: 100%|██████████| 838/838 [02:13<00:00,  6.28it/s]\n",
      "{\"Epoch\": 17, \"training loss\": 7315.532599, \"reconstruction loss\": 7265.773066, \"KLD loss\": 3.669943, \"Learning rate\": [0.001]}\n",
      "Epoch 18\n",
      "Train: 100%|██████████| 838/838 [02:13<00:00,  6.28it/s]\n",
      "{\"Epoch\": 18, \"training loss\": 7310.000553, \"reconstruction loss\": 7254.586128, \"KLD loss\": 3.883458, \"Learning rate\": [0.001]}\n",
      "Epoch 19\n",
      "Train:  38%|███▊      | 316/838 [00:50<01:14,  6.99it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Train: 100%|██████████| 838/838 [02:13<00:00,  6.28it/s]\n",
      "{\"Epoch\": 32, \"training loss\": 7223.778852, \"reconstruction loss\": 7188.78099, \"KLD loss\": 6.808309, \"Learning rate\": [0.000125]}\n",
      "Epoch 33\n",
      "Train: 100%|██████████| 838/838 [02:13<00:00,  6.27it/s]\n",
      "{\"Epoch\": 33, \"training loss\": 7221.334664, \"reconstruction loss\": 7186.452608, \"KLD loss\": 7.01639, \"Learning rate\": [0.000125]}\n",
      "Epoch 34\n",
      "Train: 100%|██████████| 838/838 [02:13<00:00,  6.28it/s]\n",
      "{\"Epoch\": 34, \"training loss\": 7218.928946, \"reconstruction loss\": 7182.350617, \"KLD loss\": 7.227651, \"Learning rate\": [0.000125]}\n",
      "Epoch 35\n",
      "Train: 100%|██████████| 838/838 [02:13<00:00,  6.28it/s]\n",
      "{\"Epoch\": 35, \"training loss\": 7218.326237, \"reconstruction loss\": 7183.348866, \"KLD loss\": 7.437597, \"Learning rate\": [6.25e-05]}\n",
      "Epoch 36\n",
      "Train:  45%|████▍     | 375/838 [01:00<01:00,  7.64it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "import json\n",
    "\n",
    "print(f\"Model: {model_id}. Training for {num_epochs} epochs\", file=sys.stderr)\n",
    "\n",
    "for epoch in range(epoch_start, num_epochs):\n",
    "  print(f\"Epoch {epoch}\", file=sys.stderr)\n",
    "  \n",
    "  # set model in training mode\n",
    "  model.train()\n",
    "  training_loss = 0.0\n",
    "  reconstruction_loss = 0.0\n",
    "  kld_loss = 0.0\n",
    "\n",
    "  for x in tqdm(train_dataloader, desc=\"Train\"):\n",
    "    optimizer.zero_grad() # clear calculated gradients\n",
    "\n",
    "    x = x.to(device)\n",
    "    \n",
    "    with torch.cuda.amp.autocast():\n",
    "      output = model(x)\n",
    "      all_loss = model.loss(kld_weight=1.0)\n",
    "      loss = all_loss[\"loss\"]\n",
    "    \n",
    "    # backpropo loss and accumuate loss stat\n",
    "    scaler.scale(loss).backward()    \n",
    "    \n",
    "    training_loss += loss.detach().item() # otherwise this would be a tensor\n",
    "    reconstruction_loss += all_loss['Reconstruction_Loss'].detach().item()\n",
    "    kld_loss += all_loss['KLD'].detach().item()\n",
    "\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    \n",
    "  # let scheduler know it's the next epoch\n",
    "  training_loss /= len(train_dataloader)\n",
    "  reconstruction_loss /= len(train_dataloader)\n",
    "  kld_loss /= len(train_dataloader)\n",
    "  \n",
    "  scheduler.step(training_loss)\n",
    "  \n",
    "  log_str = json.dumps({\n",
    "    \"Epoch\": epoch,\n",
    "    \"training loss\": round(training_loss, 6),\n",
    "    \"reconstruction loss\": round(reconstruction_loss, 6),\n",
    "    \"KLD loss\": round(kld_loss, 6),\n",
    "    \"Learning rate\": scheduler._last_lr\n",
    "  })\n",
    "\n",
    "  with open(f\"{model_store}/{model_id}/training_logs.txt\", \"a\") as log_file:\n",
    "    log_file.write(log_str + \"\\n\")\n",
    "  print(log_str, file=sys.stderr)\n",
    "  \n",
    "  torch.save(StoredModel(model, optimizer, scheduler, None),\n",
    "             f\"{model_store}/{model_id}/epoch_{epoch:02d}\" +\\\n",
    "             f\"_tr-loss_{training_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "validataion_dataloader_args = dict(batch_size=128,\n",
    "                             num_workers=0 if is_windows else 4) if has_cuda else dict(batch_size=64)\n",
    "validataion_dataloader_args[\"shuffle\"] = False\n",
    "\n",
    "validataion_dataloader = data.DataLoader(dataset, **validataion_dataloader_args)\n",
    "\n",
    "# set model in training mode\n",
    "model.eval()\n",
    "\n",
    "latent_mu = list()\n",
    "latent_log_var = list()\n",
    "\n",
    "for i, x in enumerate(tqdm(validataion_dataloader, desc=\"Validate\")):\n",
    "  x = x.to(device)\n",
    "\n",
    "  _, mus, log_vars = model.encode(x)\n",
    "  latent_mu.append(mus.detach().cpu())\n",
    "  latent_log_var.append(log_vars.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((torch.vstack(latent_mu), torch.vstack(latent_log_var)), f\"latent_vectors/{model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_divergence_raw = list()\n",
    "\n",
    "image_1 = dataset[0].to(device)\n",
    "\n",
    "for i in tqdm(range(len(dataset) - 1), desc=\"L2\"):\n",
    "  image_2 = dataset[i + 1].to(device)\n",
    "  \n",
    "  diff = (image_1 - image_2).flatten()\n",
    "  \n",
    "  L2_divergence_raw.append(torch.linalg.norm(diff, 2).cpu().item())\n",
    "  \n",
    "  image_1 = image_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.tensor(L2_divergence_raw), f\"temp_store/{model_id}/l2_divergence_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = lambda X, mn, mx: [(x - mn)/(mx - mn) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW1_part_2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02768ffc5b6a409e8a498c4d392f32ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0283c3f6ab8d4db59c360fbdac209a40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "07a14eca20f041daae89d7f24a313efb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d4725910b274893adc55eb6b921ac0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e7015b74a144561951a104c706ec89e",
       "IPY_MODEL_1644bd1faf584290bfa440f0c91631b3"
      ],
      "layout": "IPY_MODEL_f5101a0c7f6447f0a339f48c2d5d50d1"
     }
    },
    "13ca4f4139f049eab3013edc25c5cb1b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1644bd1faf584290bfa440f0c91631b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13ca4f4139f049eab3013edc25c5cb1b",
      "placeholder": "​",
      "style": "IPY_MODEL_02768ffc5b6a409e8a498c4d392f32ad",
      "value": " 381/381 [00:28&lt;00:00, 13.52it/s]"
     }
    },
    "1805948e77c0451a9e059c5c4bf179f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1e7015b74a144561951a104c706ec89e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Validate: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07a14eca20f041daae89d7f24a313efb",
      "max": 381,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9bc1b9387d774436ac5e5364564e04ee",
      "value": 381
     }
    },
    "2173829b4cbe497c9de00d80a7268f5e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e1997cd529542378c714b0e756228cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_44f69c76d6504365bf2ceea26ddb4cb0",
       "IPY_MODEL_89c64138bb524eb292f61a1f667c2e36"
      ],
      "layout": "IPY_MODEL_9d28ab07d37b43239c5e4ab76bd42a47"
     }
    },
    "3fa5a9ca37344da2be24670c75153355": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44f69c76d6504365bf2ceea26ddb4cb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "Train:  13%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2173829b4cbe497c9de00d80a7268f5e",
      "max": 4513,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b3616ce23d6e458587a869dcda5b0e65",
      "value": 585
     }
    },
    "49e8cce1980b46f69e2271f61680dd47": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff8d7ad423514805aa787c690a1af364",
       "IPY_MODEL_4c6fb19bcea64ca6950ab21c526cc7fc"
      ],
      "layout": "IPY_MODEL_e4a224892c794b3e830645e2ff44a478"
     }
    },
    "4c6fb19bcea64ca6950ab21c526cc7fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c80f27fe1e4543bf93d95a0592b5caea",
      "placeholder": "​",
      "style": "IPY_MODEL_80cfd4dc87644e3db22cd48e1a77f6e2",
      "value": " 4513/4513 [04:42&lt;00:00, 15.97it/s]"
     }
    },
    "596b682110674f20934a06addff6d8f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "Epoch:   2%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb87e4d9cb9f49d28a2e070bc7899749",
      "max": 43,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1805948e77c0451a9e059c5c4bf179f9",
      "value": 1
     }
    },
    "5c0dee334a114a52abd20b7a1b96d568": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_596b682110674f20934a06addff6d8f6",
       "IPY_MODEL_5ee5b74cab264a4e84bc6e20bc850bc7"
      ],
      "layout": "IPY_MODEL_a533314e9e2f4d23a31c298a0683c486"
     }
    },
    "5ee5b74cab264a4e84bc6e20bc850bc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f87e2946789478eafa38e091d34ab37",
      "placeholder": "​",
      "style": "IPY_MODEL_0283c3f6ab8d4db59c360fbdac209a40",
      "value": " 1/43 [05:45&lt;3:34:36, 306.59s/it]"
     }
    },
    "734209de749448659ab4cd1d83138bbc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80cfd4dc87644e3db22cd48e1a77f6e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89c64138bb524eb292f61a1f667c2e36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3fa5a9ca37344da2be24670c75153355",
      "placeholder": "​",
      "style": "IPY_MODEL_9fd5d7540f954a72b1da87f751226d91",
      "value": " 585/4513 [00:51&lt;04:28, 14.62it/s]"
     }
    },
    "9bc1b9387d774436ac5e5364564e04ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9d28ab07d37b43239c5e4ab76bd42a47": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f87e2946789478eafa38e091d34ab37": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fd5d7540f954a72b1da87f751226d91": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a533314e9e2f4d23a31c298a0683c486": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3616ce23d6e458587a869dcda5b0e65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bf1698340c0d43279c1856c571d6cdc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c80f27fe1e4543bf93d95a0592b5caea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4a224892c794b3e830645e2ff44a478": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb87e4d9cb9f49d28a2e070bc7899749": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5101a0c7f6447f0a339f48c2d5d50d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff8d7ad423514805aa787c690a1af364": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Train: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_734209de749448659ab4cd1d83138bbc",
      "max": 4513,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf1698340c0d43279c1856c571d6cdc6",
      "value": 4513
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
